# ğŸš— Vehicle Insurance Prediction â€“ End-to-End MLOps Project

Welcome to the **Vehicle Insurance Prediction MLOps Project**! This project is designed to **predict whether a customer will opt for vehicle insurance** based on their personal and vehicle-related details using a machine learning model.

In addition to delivering accurate predictions, this project is built to **impress recruiters, engineers, and MLOps enthusiasts** by showcasing an **end-to-end production-grade ML pipeline**. Leveraging tools like **Docker, GitHub Actions, MongoDB Atlas, AWS (ECR, EC2, S3), and FastAPI**, the project seamlessly covers everything from data ingestion to real-time deployment.

---


---

## ğŸŒŸ Key Highlights

âœ… **Modular Architecture**  
ğŸ” **Complete MLOps Lifecycle**  
â˜ï¸ **Cloud Integration**: MongoDB Atlas, AWS S3, EC2, ECR  
ğŸš€ **CI/CD Automation**: GitHub Actions + Self-hosted EC2 Runner  
ğŸ“Š **ML Pipeline**: Ingestion â†’ Validation â†’ Transformation â†’ Training â†’ Evaluation â†’ Deployment  
âš¡ **FastAPI Interface**: Realtime prediction UI  
ğŸ³ **Dockerized Deployment** on AWS EC2  

---

## ğŸ—ï¸ Project Setup

### 1ï¸âƒ£ Environment Setup

```bash
python -m venv vehicle-env
source vehicle-env/bin/activate 
pip install -r requirements.txt
pip list  # Verify installed packages
```

- Create the project folder structure.
- Add local package support using `setup.py` and `pyproject.toml`. 

---

## ğŸ“¦ MongoDB Atlas Integration

1. Create a **MongoDB Atlas** account.
2. Launch a free **M0 cluster**.
3. Add your **username/password** and set IP access to `0.0.0.0/0`.
4. Copy your **Python connection string**.
5. Create and run `notebooks/mongoDB_demo.ipynb` to upload your dataset.
6. Confirm upload via: *Clusters â†’ Collections â†’ Browse Data*.

---

## ğŸ§ª Logging, Exception Handling, & EDA

- Implemented custom logging and exception handling (`demo.py`)
- Performed **Exploratory Data Analysis (EDA)** and feature engineering in `notebooks/`

---

## ğŸ“… Data Ingestion

ğŸ”¹ MongoDB connection handled in: `configuration/mongo_db_connection.py`  
ğŸ”¹ Created pipeline entities:  
   - `entity/config_entity.py`  
   - `entity/artifact_entity.py`  
ğŸ”¹ Used `data_access/proj1_data.py` for DB read/write  
ğŸ”¹ Ingestion logic in: `components/data_ingestion.py`

#### ğŸ” Environment Variables Setup

```bash
# Linux/macOS
export MONGODB_URL="your_connection_string"
echo $MONGODB_URL

# Windows
setx MONGODB_URL "your_connection_string"
```

---

## âœ… Data Validation, Transformation & Model Training

ğŸ“ Schema: `config/schema.yaml`  
ğŸ“Œ Modules:  
- Validation: `components/data_validation.py`  
- Transformation: `components/data_transformation.py`  
- Model Training: `components/model_trainer.py`

---

## â˜ï¸ AWS S3 for Model Registry

1. Create an **IAM User** (`firstproj`) with `AdministratorAccess`.
2. Download and securely store **Access Keys**.
3. Export keys as environment variables:

```bash
export AWS_ACCESS_KEY_ID="your_key"
export AWS_SECRET_ACCESS_KEY="your_secret"
```

4. Create S3 Bucket: `my-model-mlopsproj` (region: `us-east-1`)
5. Setup S3 connection in: `configuration/aws_connection.py`

ğŸ“Œ Constants to define:

```python
MODEL_EVALUATION_CHANGED_THRESHOLD_SCORE = 0.02
MODEL_BUCKET_NAME = "my-model-mlopsproj"
MODEL_PUSHER_S3_KEY = "model-registry"
```

---

## ğŸ“Š Model Evaluation & Pushing to S3

- Compares performance with previous model.
- Pushes the best-performing model to AWS S3 for production use.

---

## ğŸ§  FastAPI-based Realtime Prediction

1. Build FastAPI interface in `app.py`
2. Create web UI using:

```
templates/
static/
```

- Endpoints:
  - `/`: Home Page
  - `/predict`: Make predictions
  - `/training`: Trigger training

---

## ğŸ”„ CI/CD Pipeline â€“ Docker, GitHub Actions, EC2

### ğŸ§± Setup Steps:

1. **Dockerize App**:
   - `Dockerfile`
   - `.dockerignore`

2. **CI/CD Workflow**:
   - `.github/workflows/aws.yaml`

3. **GitHub â†’ AWS Integration**:
   - Goto IAM User
   - Generate Access Keys
   - Add secrets to GitHub:
     - `AWS_ACCESS_KEY_ID`
     - `AWS_SECRET_ACCESS_KEY`
     - `AWS_DEFAULT_REGION`
     - `ECR_REPO`

4. **Create ECR Repo**: `vehicleproj`

5. **Launch EC2 Instance**: `vehicledata-machine` (Ubuntu)

6. **Install Docker on EC2**:

```bash
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker ubuntu
newgrp docker
```

7. **Add Self-Hosted Runner on EC2**:
   - Configure using GitHub Actions Settings â†’ Runners

8. **Allow Port 5080 on EC2**:
   - Go to EC2 â†’ Security Groups â†’ Inbound Rules â†’ Add TCP rule for **Port 5080**

---

## ğŸš€ Deploy & Access

âœ… Push code â†’ GitHub Actions triggers CI/CD  
âœ… Docker image built â†’ pushed to ECR  
âœ… EC2 pulls image â†’ launches container  

ğŸŒ **Access the app** at:  
```bash
http://<EC2-PUBLIC-IP>:5080
```

ğŸ” **Trigger model training**:  
```bash
http://<EC2-PUBLIC-IP>:5080/training
```

---

---

## ğŸ“‚ Project Structure (Simplified)

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/               # Core pipeline logic (ingestion, validation, training, etc.)
â”‚   â”œâ”€â”€ configuration/            # AWS and MongoDB configurations
â”‚   â”œâ”€â”€ data_access/              # Handles DB CRUD operations
â”‚   â”œâ”€â”€ entity/                   # Defines structured entities for configs and artifacts
â”‚   â”œâ”€â”€ pipeline/                 # Training orchestration logic
â”‚   â””â”€â”€ aws_storage/              # AWS S3 utility functions
â”œâ”€â”€ templates/                    # FastAPI HTML templates
â”œâ”€â”€ static/                       # CSS/JS assets
â”œâ”€â”€ notebooks/                    # EDA & MongoDB upload demos
â”œâ”€â”€ app.py                        # FastAPI backend server
â”œâ”€â”€ demo.py                       # Logger and error handler test script
â”œâ”€â”€ Dockerfile                    # Docker configuration
â”œâ”€â”€ .github/workflows/aws.yaml   # GitHub Actions CI/CD pipeline
â”œâ”€â”€ setup.py                      # Local module installer
â”œâ”€â”€ pyproject.toml                # Metadata and packaging config
â””â”€â”€ requirements.txt              # Python dependencies
```

---

## ğŸ™Œ Summary

This project is an **industry-grade, cloud-integrated, CI/CD-enabled ML pipeline** that solves a **real-world classification problem**: predicting whether a user will opt for vehicle insurance. It's a complete ML system packaged with training, monitoring, deployment, and a realtime prediction interface â€” perfect for showcasing your **ML engineering and MLOps expertise**.

---





