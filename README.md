# ðŸš— Vehicle Insurance Prediction - MLOps End-to-End Project

Welcome to the **Vehicle Insurance Prediction MLOps Project**! This project is built to impressâ€”crafted using production-ready architecture and cutting-edge tools like **Docker, GitHub Actions, MongoDB, AWS ECR/EC2/S3**, and more. It's designed to show your MLOps knowledge in actionâ€”from development to deployment.

---

## ðŸŒŸ Key Highlights

- âœ… Fully Modular Architecture
- ðŸ” End-to-End MLOps Lifecycle
- â˜ï¸ Cloud-Integrated: MongoDB Atlas, AWS S3, EC2, ECR
- ðŸ“¦ CI/CD: GitHub Actions + Self-hosted EC2 Runner
- ðŸ“ˆ ML Workflow: Data Ingestion to Model Deployment
- ðŸ“Š Realtime Prediction Interface using FastAPI
- ðŸ³ Dockerized Deployment to AWS EC2

---

## ðŸ› ï¸ Project Setup Steps

### 1. ðŸš§ Project Initialization
- Run `template.py` to create the project folder structure.
- Add local package import support using `setup.py` and `pyproject.toml`. ([Learn more](./crashcourse.txt))

```bash
conda create -n vehicle python=3.10 -y
conda activate vehicle
pip install -r requirements.txt
pip list  # To verify packages
```

---

## ðŸ“¦ MongoDB Setup (Atlas)
1. Sign up at MongoDB Atlas and create a new project.
2. Create a free M0 cluster.
3. Set up username & password, allow IP access (0.0.0.0/0).
4. Copy connection string (Python 3.6+ driver).
5. Create `notebook/mongoDB_demo.ipynb` and push dataset to MongoDB.
6. Verify upload on Atlas â†’ Database â†’ Browse Collection.

---

## ðŸ§ª Logging, Exception Handling, and EDA
- Logger and exception handler implemented and tested via `demo.py`.
- Performed EDA and feature engineering notebooks added to `notebooks/`.

---

## ðŸ“¥ Data Ingestion Module
- MongoDB connection setup in `configuration.mongo_db_connection.py`
- Create pipeline entities (`config_entity.py`, `artifact_entity.py`)
- Fetch and transform data using `data_access/proj1_data.py`
- Setup ingestion in `components.data_ingestion.py`
- Environment variable setup:

```bash
# For bash
export MONGODB_URL="your_mongodb_connection_string"
echo $MONGODB_URL

# For Windows
setx MONGODB_URL "your_mongodb_connection_string"
```

---

## âœ… Data Validation, Transformation, and Model Training
- Schema defined in `config/schema.yaml`
- Validation logic in `components.data_validation.py`
- Transformation logic in `components.data_transformation.py`
- Model training in `components/model_trainer.py`

---

## â˜ï¸ AWS Setup for Model Registry
1. Create IAM user (`firstproj`) with `AdministratorAccess`.
2. Create and download Access Keys (store securely).
3. Set environment variables:

```bash
export AWS_ACCESS_KEY_ID="..."
export AWS_SECRET_ACCESS_KEY="..."
```

4. Create S3 Bucket: `my-model-mlopsproj` (region: us-east-1).
5. Configure S3 connection in `configuration.aws_connection.py`.
6. Define constants:
```python
MODEL_EVALUATION_CHANGED_THRESHOLD_SCORE = 0.02
MODEL_BUCKET_NAME = "my-model-mlopsproj"
MODEL_PUSHER_S3_KEY = "model-registry"
```

---

## ðŸ“Š Model Evaluation and Model Pusher
- Evaluate performance against previous model.
- Push trained model to AWS S3.

---

## ðŸ§  Prediction Pipeline + FastAPI
1. Create `app.py` for FastAPI interface.
2. Add `static/` and `template/` folders for web UI.

---

## ðŸ”„ CI/CD Pipeline (Docker + GitHub Actions + EC2)
### Step-by-step:
1. Create Dockerfile and `.dockerignore`
2. Create `.github/workflows/aws.yaml`
3. Create IAM user: `usvisa-user`, download credentials
4. Create ECR repository: `vehicleproj`
5. Launch EC2 Ubuntu Instance: `vehicledata-machine`
6. Install Docker on EC2:
```bash
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker ubuntu
newgrp docker
```
7. Setup GitHub self-hosted runner on EC2.
8. Add GitHub secrets:
   - `AWS_ACCESS_KEY_ID`
   - `AWS_SECRET_ACCESS_KEY`
   - `AWS_DEFAULT_REGION`
   - `ECR_REPO`

9. Open EC2 port 5080:
   - EC2 > Security Group > Inbound Rules > Add TCP rule for port 5080

---

## ðŸš€ Deploy & Access
- Push code to GitHub â†’ triggers CI/CD
- Docker image is built, pushed to ECR
- EC2 pulls image and runs container
- Access app at `http://<EC2-PUBLIC-IP>:5080`
- Trigger training at: `http://<EC2-PUBLIC-IP>:5080/training`

---

## ðŸ“ Directory Structure (Simplified)
```bash
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ configuration/
â”‚   â”œâ”€â”€ data_access/
â”‚   â”œâ”€â”€ entity/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ aws_storage/
â”œâ”€â”€ templates/
â”œâ”€â”€ static/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ app.py
â”œâ”€â”€ demo.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .github/workflows/aws.yaml
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
```

---

## ðŸ™Œ Final Notes
This project demonstrates an industry-grade, modular MLOps pipelineâ€”covering every stage from raw data to deployment with monitoring, versioning, and CI/CD integration. Perfect for showcasing your full-stack ML/DevOps capabilities!

---

> âš¡ Made with passion, Python, and a lot of Docker containers.

---

Ready to deploy or learn? Fork it, run it, or make it your own. ðŸ’¡

